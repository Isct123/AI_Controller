# AI Controller

The AI can:

- Click anywhere it likes on your screen
- Type whatever it likes
- View your screen

This intends to make a multimodal LLM that can see your screen and also interact with it and perform actual actions.

(Finished in about 20 mins through vibecoding so it doesn't work as well as it intends to. Will work towards improvement.)
